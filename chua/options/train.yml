name: Track1
use_tb_logger: true
suffix: ~ # add suffix to saved images
model: srgan #other model names to be given and listed at models/_init_.py create_model()
distortion: sr
scale: 4
crop_border: ~ # crop border when evaluation. If None(~), crop the scale pixels
gpu_ids: [0, 1]

datasets:
  train: # the 1st train dataset
    name: FYP_TRAIN
    mode: chua
    dataroot_GT: chua/TrainingSet/allpatches
    kernel_folder: chua/TrainingSet/kernels
    noise_folder: chua/TrainingSet/noises

    use_shuffle: true
    n_workers: 24
    batch_size: 28 #14,28,53 ------1484 training image in total
    GT_size: 128
    use_flip: true
    use_rot: false
    color: RGB

  #val:
  #name: FYP_VAL
  #mode: LR
  #dataroot_LQ: chua/ValidationSet #validation set
  #dataroot_GT: /mnt/data/NTIRE2020/realSR/track1/DIV2K_valid_HR
  #dataroot_GT: None

  #num_val: 20
  #use_shuffle: false
  #color: RGB

#### network structures
network_G:
  which_model_G: RRDBNet
  in_nc: 3
  out_nc: 3
  nf: 64
  nb: 23
  upscale: 4

network_D:
  which_model_D: NLayerDiscriminator
  in_nc: 3
  nf: 64
  nlayer: 3
  norm_layer: instancenorm # batchnorm

#### path
path:
  pretrain_model_G: pretrained_model/esrgan/RRDB_ESRGAN_x4.pth #Test phase
  results_root: ./results/
  val_images: ./val_image_output
  models: chua #Training phase -- save model path

#### training settings: learning rate scheme, loss
train:
  lr_G: !!float 1e-4
  weight_decay_G: 0
  beta1_G: 0.9
  beta2_G: 0.99
  lr_D: !!float 1e-4
  weight_decay_D: 0
  beta1_D: 0.9
  beta2_D: 0.99
  lr_scheme: MultiStepLR

  niter: 1000 #numtrainingdata/batchsize #yoon:40000
  warmup_iter: -1 # no warm up
  lr_steps: [4000, 8000, 12000]
  lr_gamma: 0.5

  pixel_criterion: l1
  pixel_weight: !!float 1e-2
  feature_criterion: l1
  feature_weight: 1
  gan_type: ragan # gan | ragan
  gan_weight: !!float 5e-3

  D_update_ratio: 1
  D_init_iters: 0

  manual_seed: 0
  val_freq: !!float 2e3

#### logger
logger:
  print_freq: 100000
  save_checkpoint_freq: !!float 2e3
